<!DOCTYPE html>
<html lang="en">

<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link rel="stylesheet" type="text/css" href="../../../../default.css" />
<link rel="alternative" type="application/atom+xml" title="Pipeline from Input, or Pipeline to Output?" href="../../../../index.xml" />
<title>Pipeline from Input, or Pipeline to Output?</title>
</head>

<body>
<nav>
  <ul>
    <li>
      <a href="../../../../index.html">index</a>
    </li>
    <li>
      <a href="../../../../index.xml">
        <img class="feed" src="../../../../feed.png" title="feed" />
      </a>
    </li>
    <li><a href="mailto:laec@proton.me">contact</a></li>
  </ul>
</nav>
  <main>
    <h1>Pipeline from Input, or Pipeline to Output?</h1>
<p>Let say you are going to implement an HTTP service, we can post it a
list of actions, it will perform those actions and return a list of
results.</p>
<p>The first version is simple, read the actions, process them, then
write the results.</p>
<pre><code class="language-java">List&lt;Action&gt; actions =
  readAll(request);

List&lt;Result&gt; results =
  invokeAll(actions);

results.forEach(this::write);
</code></pre>
<p>Everything seems to work fine but after a while clients are starting
to get timeouts.</p>
<p>It turns out that some actions take longer time to complete, say about
1 second, so if you send 10 of these actions to the service, it will
take 10 seconds for the client to see the response after sending the
request, because the service processes everything before sending the
response. Imagine a client sends hundreds or thousands of actions in a
request, it will take a very long time to see the first byte of the
response. And because the client has set its read timeout to be less
than that, it timed out.</p>
<p>Apart from increasing the client timeout, you decided to improve the
service, turning it into a pipeline (<code>Stream</code> is lazy sequence):</p>
<pre><code class="language-java">Stream&lt;Action&gt; actions =
  read(request);

Stream&lt;Result&gt; results =
  actions.map(this::invoke);

results.forEach(this::write);
</code></pre>
<p>It will now read, invoke, output each of the actions one at a time as
a pipeline. Clients will see the results incrementally as they
complete, no need to wait for everything to be processed first. And this
keeps data flowing continuously, avoiding idle timeouts.</p>
<p>But then you remembered this is no good as it could cause <a href="../25/tcp-deadlock.html">TCP
Deadlocks</a>.</p>
<p>Now what other options are there? If a full pipeline is no good, maybe
a partial pipeline would be okay?</p>
<p>For the next option, the service can pipeline from the input, but
collect all the results into a list in memory, once complete, write
them out.</p>
<pre><code class="language-java">Stream&lt;Action&gt; actions =
  read(request);

List&lt;Result&gt; results =
  actions
    .map(this::invoke)
    .collect(toList());

results.forEach(this::write);
</code></pre>
<p>This means while the client sends the list of actions, the service
reads and processes the actions one at a time, when the service can't
read fast enough because it encounters slow actions, TCP applies back
pressure to the client, slowing down the rate which it sends data to
the service. The client should see the response soon after it finishes
sending a large request, as processing was done at the same time while
the data was being sent to the service. And since it drains the input
before output, it does not deadlock.</p>
<p>While this is a perfectly fine solution in many cases, in this
specific case there is still a problem. Because TCP has buffers, when
the client finishes sending and switches to waiting for the response,
there maybe enough slow actions left in the buffers (especially with
compression turned on) yet to be received and read by the service,
enough to cause a read timeout.</p>
<p>How about another option, if instead all the actions are read into a
list, then pipeline from processing to output?</p>
<pre><code class="language-java">List&lt;Action&gt; actions =
  readAll(request);

Stream&lt;Result&gt; results =
  actions
    .stream()
    .map(this::invoke);

results.forEach(this::write);
</code></pre>
<p>With this, the service would finish loading all actions into memory
soon after the client finishes sending them, as request parsing is
typically fast. Then the service starts processing and writing the
results back one at a time, the client will see each result
incrementally in the response stream. This way we avoids the request
buffering issues with the previous approach.</p>
<p>Does this solve the problem then? Well, it depends. This approach,
like the deadlock prone implementation, requires the client to read
the response output for the actual processing to happen (except for
the first few, if their outputs fit into the TCP buffers). This may or
may not be acceptable depending on the requirements. And what should
the HTTP response code be? If it relies on knowing the outcome of the
actions, then this approach is a no go, since the response code is the
first thing to be sent, it would be fine though if the response code
is generic, and each result has their own result codes instead, again,
depends on the requirements.</p>
<p>So it looks like there is not a satisfactory solution so far. There
are other options though, but they will probably have their own set of
trade offs. Sometimes there is just no perfect solution, but one can
have options, and can pick one that has the best fit.</p>
    <p>
      <time itemprop="datePublished" datetime="2019-07-26">2019-07-26</time>
    </p>
  </main>
</body>

</html>
